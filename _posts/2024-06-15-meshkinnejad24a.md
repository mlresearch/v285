---
title: Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks
booktitle: 'UniReps: 2nd Edition of the Workshop on Unifying Representations in Neural
  Models'
year: '2024'
url: https://openreview.net/forum?id=fS41j9Ksds
abstract: Contrastive representation learning has emerged as a promising technique
  for continual learning as it can learn representations that are robust to catastrophic
  forgetting and generalize well to unseen future tasks. Previous work in continual
  learning has addressed forgetting by using previous task data and trained models.
  Inspired by event models created and updated in the brain, we propose a new mechanism
  that takes place during task boundaries, i.e., when one task finishes and another
  starts. By observing the redundancy-inducing ability of contrastive loss on the
  output of a neural network, our method leverages the first few samples of the new
  task to identify and retain parameters contributing most to the transfer ability
  of the neural network, freeing up the remaining parts of the network to learn new
  features. We evaluate the proposed methods on benchmark computer vision datasets
  including CIFAR10 and TinyImagenet and demonstrate state-of-the-art performance
  in task-incremental, class-incremental, and domain-incremental continual learning
  scenarios.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: meshkinnejad24a
month: 0
tex_title: Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks
firstpage: 152
lastpage: 169
page: 152-169
order: 152
cycles: false
bibtex_author: Meshkinnejad, Rouzbeh and Mei, Jie and Zhang, Zeduo and Lizotte, Daniel
  J and Mohsenzadeh, Yalda
author:
- given: Rouzbeh
  family: Meshkinnejad
- given: Jie
  family: Mei
- given: Zeduo
  family: Zhang
- given: Daniel J
  family: Lizotte
- given: Yalda
  family: Mohsenzadeh
date: 2024-06-15
address:
container-title: 'Proceedings of UniReps: the Second Edition of the Workshop on Unifying
  Representations in Neural Models'
volume: '285'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v285/main/assets/meshkinnejad24a/meshkinnejad24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
