---
title: 'Joint Learning for Visual Reconstruction from the Brain Activity: Hierarchical
  Representation of Image Perception with EEG-Vision Transformer'
booktitle: 'UniReps: 2nd Edition of the Workshop on Unifying Representations in Neural
  Models'
year: '2024'
url: https://openreview.net/forum?id=SjXJOsLi1X
abstract: Reconstructing visual stimuli from brain activity is a challenging problem,
  particularly when using EEG data, which is more affordable and accessible than fMRI
  but noisier and lower in spatial resolution. In this paper, we present Hierarchical-ViT,
  a novel framework designed to improve the quality and precision of EEG-based image
  reconstruction by integrating hierarchical visual feature extraction, vision transformer-based
  EEG (EEG-ViT) processing, and CLIP-based joint learning. Inspired by the hierarchical
  nature of the human visual system, our model progressively captures complex visual
  features-such as edges, textures, and shapes-through a multi-stage processing approach.
  These features are aligned with EEG signals processed by the EEG-ViT model, allowing
  for the creation of a shared latent space that enhances contrastive learning. A
  StyleGAN is then employed to generate high-resolution images from these aligned
  representations. We evaluated our method on two benchmark datasets, EEGCVPR40 and
  ThoughtViz, achieving superior results compared to existing approaches in terms
  of Inception Score (IS), Kernel Inception Distance (KID), and Frchet Inception Distance
  (FID) for EEGCVPR, and IS and KID for the ThoughtViz dataset. Through an ablation
  study, we underscored the feasibility of hierarchical feature extraction, while
  multivariate analysis of variance (MANOVA) test confirmed the distinctiveness of
  the learned feature spaces.  In conclusion, our results show the feasibility and
  uniqueness of using hierarchical filtering of perceived images combined with EEG-ViT-based
  features to improve brain decoding from EEG data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: akbari24a
month: 0
tex_title: 'Joint Learning for Visual Reconstruction from the Brain Activity: Hierarchical
  Representation of Image Perception with {EEG}-Vision Transformer'
firstpage: 204
lastpage: 218
page: 204-218
order: 204
cycles: false
bibtex_author: Akbari, Ali and Arani, Kosar Sanjar and Yousefnezhad, Tony and Mirian,
  Maryam and Arasteh, Emad
author:
- given: Ali
  family: Akbari
- given: Kosar Sanjar
  family: Arani
- given: Tony
  family: Yousefnezhad
- given: Maryam
  family: Mirian
- given: Emad
  family: Arasteh
date: 2024-06-15
address:
container-title: 'Proceedings of UniReps: the Second Edition of the Workshop on Unifying
  Representations in Neural Models'
volume: '285'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v285/main/assets/akbari24a/akbari24a.pdf
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v285/main/assets/assets/akbari24a/akbari24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
