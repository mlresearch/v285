---
title: Vision and language representations in multimodal AI models and human social
  brain regions during natural movie viewing
booktitle: 'UniReps: 2nd Edition of the Workshop on Unifying Representations in Neural
  Models'
year: '2024'
url: https://openreview.net/forum?id=pS1UjuYuJu
abstract: Recent work in NeuroAI suggests that representations in modern AI vision
  and language models are highly aligned with each other and human visual cortex.
  In addition, training AI vision models on language-aligned tasks (e.g., CLIP-style
  models) improves their match to visual cortex, particularly in regions involved
  in social perception, suggesting these brain regions may be similarly "language
  aligned". This prior work has primarily investigated only static stimuli without
  language, but in our daily lives, we experience the dynamic visual world and communicate
  about it using language simultaneously. To understand the processing of vision and
  language during natural viewing, we fit an encoding model to predict voxel-wise
  responses to an audiovisual movie using visual representations from both purely
  visual and language-aligned vision transformer models and paired language transformers.
  We first find that in naturalistic settings, there is remarkably low correlation
  between representations in vision and language models and both predict social perceptual
  and language regions well. Next, we find that language-alignment does not improve
  a vision model embedding’s match to neural responses in social perceptual regions,
  despite these regions being well predicted by both vision and language embeddings.
  Preliminary analyses, however, suggest that vision-alignment does improve a language
  model’s ability to match neural responses in language regions during audiovisual
  processing.  Our work demonstrates the importance of testing multimodal AI models
  in naturalistic settings and reveals differences between language alignment in modern
  AI models and the human brain.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: small24a
month: 0
tex_title: Vision and language representations in multimodal {AI} models and human
  social brain regions during natural movie viewing
firstpage: 69
lastpage: 84
page: 69-84
order: 69
cycles: false
bibtex_author: Small, Hannah and Masson, Haemy Lee and Mostofsky, Stewart and Isik,
  Leyla
author:
- given: Hannah
  family: Small
- given: Haemy Lee
  family: Masson
- given: Stewart
  family: Mostofsky
- given: Leyla
  family: Isik
date: 2024-06-15
address:
container-title: 'Proceedings of UniReps: the Second Edition of the Workshop on Unifying
  Representations in Neural Models'
volume: '285'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v285/main/assets/small24a/small24a.pdf
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v285/main/assets/assets/small24a/small24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
